{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fact Verification and Extraction of Climate-Related Claims"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINER: Claim Classification (Step 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, TrainingArguments, Trainer\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CC_Train_Arguments():\n",
    "    ev_path='./data/evidence.json'\n",
    "    train_claims_path = './data/train-claims.json'\n",
    "    cc_model_name = 'roberta-large-mnli'\n",
    "    cc_training_name = './models/claim_classification_training_folder'\n",
    "    cc_save_dir = './models/claim_classification_trained_model'\n",
    "    dev_claims_path = './data/dev-claims.json'\n",
    "    dev_claims_pickle = './pickles/dev_claims.pkl'\n",
    "    bootstrap_pickle = './pickles/bootstrap_pairs.pkl'\n",
    "    include_bootstrap = False\n",
    "    learning_rate=1e-5\n",
    "    num_train_epochs=2\n",
    "    include_dev = True # Change to 'True' to include dev in final train run\n",
    "\n",
    "my_args = CC_Train_Arguments()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map claim labels to numbered labels\n",
    "label_dict ={\n",
    "    \"REFUTES\" : 0,\n",
    "    \"NOT_ENOUGH_INFO\":1,\n",
    "    \"SUPPORTS\": 2,    \n",
    "    \"DISPUTED\":3\n",
    "}\n",
    "\n",
    "# Build evidence dataframe\n",
    "def build_evidence(path):\n",
    "    print(\"Reading evidence from %s ...\" % path, end=\"\")\n",
    "    with open(path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    print(\"done.\")\n",
    "    evidence_list = []\n",
    "    for ev_id, text in data.items():\n",
    "        evidence_list.append([ev_id,text])\n",
    "    headers = [\"id\",\"text\"]\n",
    "    evidence = pd.DataFrame(evidence_list, columns=headers)\n",
    "    print(\"Number of ev: \", len(evidence))\n",
    "    return evidence\n",
    "\n",
    "# Build claims dataframe\n",
    "def build_claims(path):\n",
    "\n",
    "    print(\"Reading claims from %s ...\" % path,end=\"\")\n",
    "    with open(path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    claims = []\n",
    "    print(\"done.\")\n",
    "    for claim, info in data.items():\n",
    "        claims.append([claim,info['claim_text'],info['claim_label'],info['evidences']])\n",
    "    headers = [\"id\",\"text\",\"claim_label\",\"evidences\"]\n",
    "    claims = pd.DataFrame(claims, columns=headers)\n",
    "    print(\"Number of claims: \", len(claims))\n",
    "    return claims\n",
    "\n",
    "# Build ev-claim pairs for training\n",
    "def build_pairs(claims, evidence):\n",
    "\n",
    "    print(\"Building pairs ...\")\n",
    "\n",
    "    pairs = []\n",
    "    \n",
    "    for _, row in tqdm(claims.iterrows(), total=len(claims)):\n",
    "        if row['claim_label'] != \"DISPUTED\":\n",
    "            evidences = evidence[evidence['id'].isin(row['evidences'])]['text'].to_list()\n",
    "            for e in evidences:\n",
    "                pairs.append([row['text'],e,label_dict[row['claim_label']]])\n",
    "\n",
    "    headers = [\"claim_text\",\"ev_text\", \"labels\"]\n",
    "    pairs = pd.DataFrame(pairs, columns=headers)\n",
    "    print(\"Total training pairs:\",len(pairs))\n",
    "    for item in label_dict:\n",
    "        print(\"%15s: %d\" % (item, len(pairs[pairs['labels']==label_dict[item]])))\n",
    "        \n",
    "    return pairs\n",
    "\n",
    "# Append bootstrapped pairs (for dev only - not used in final implementation)\n",
    "def append_bootstrapped_pairs(pairs):\n",
    "    try:\n",
    "        with open(my_args.bootstrap_pickle, 'rb') as f:\n",
    "            bootstrap_pairs = pickle.load(f)\n",
    "        pairs = pd.concat([pairs,bootstrap_pairs])\n",
    "        print(\"Added %d bootstrapped pairs. Total pairs now %d\" % (len(bootstrap_pairs), len(pairs)))\n",
    "        for item in label_dict:\n",
    "            print(\"%15s: %d\" % (item, len(pairs[pairs['labels']==label_dict[item]])))\n",
    "    except:\n",
    "        print(\"No bootstrapped pairs located.\")\n",
    "    return pairs\n",
    "\n",
    "# Mapped preprocessing function for ev-claim text pairs\n",
    "def preprocess_function(item):\n",
    "    \n",
    "    claim = item['claim_text']\n",
    "    evidence = item['ev_text']\n",
    "    encoded_input = tokenizer(\n",
    "        [[claim,evidence]],\n",
    "        add_special_tokens=True,\n",
    "        max_length=128, \n",
    "        truncation = True,\n",
    "        padding='max_length', \n",
    "        return_attention_mask=True, \n",
    "        return_tensors='pt' \n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'input_ids': encoded_input['input_ids'].squeeze(),\n",
    "        'attention_mask': encoded_input['attention_mask'].squeeze(),\n",
    "        'labels': item['labels']\n",
    "    }\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading claims from ./data/train-claims.json ...done.\n",
      "Number of claims:  1228\n",
      "Reading claims from ./data/dev-claims.json ...done.\n",
      "Number of claims:  154\n",
      "Reading evidence from ./data/evidence.json ...done.\n",
      "Number of ev:  1208827\n",
      "Building pairs ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1382/1382 [00:37<00:00, 36.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training pairs: 4163\n",
      "        REFUTES: 514\n",
      "NOT_ENOUGH_INFO: 2135\n",
      "       SUPPORTS: 1514\n",
      "       DISPUTED: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "claims = build_claims(my_args.train_claims_path)\n",
    "if my_args.include_dev:\n",
    "    claims = pd.concat([claims,build_claims(my_args.dev_claims_path)])\n",
    "evidence = build_evidence(my_args.ev_path)\n",
    "pairs = build_pairs(claims,evidence)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95726cacef5b4fce973db1f8c9af1cfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4163 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "model_name = my_args.cc_model_name\n",
    "training_name = my_args.cc_training_name\n",
    "save_dir = my_args.cc_save_dir\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "\n",
    "dataset = Dataset.from_pandas(pairs)\n",
    "encoded_dataset = dataset.map(preprocess_function)\n",
    "encoded_dataset.shuffle()\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "args = TrainingArguments(\n",
    "    training_name,\n",
    "    learning_rate=my_args.learning_rate,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=my_args.num_train_epochs,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    "    report_to=None,\n",
    "    save_strategy='no'\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_dataset\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: claim_text, ev_text. If claim_text, ev_text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "c:\\Program Files\\VirtualEnvs\\py_109_NLP\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 4163\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1042\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e578d02429b435dbc6bea6f88eb2a4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1042 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6615, 'learning_rate': 5.201535508637236e-06, 'epoch': 0.96}\n",
      "{'loss': 0.3421, 'learning_rate': 4.0307101727447224e-07, 'epoch': 1.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 484.6454, 'train_samples_per_second': 17.18, 'train_steps_per_second': 2.15, 'train_loss': 0.49361161398567305, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1042, training_loss=0.49361161398567305, metrics={'train_runtime': 484.6454, 'train_samples_per_second': 17.18, 'train_steps_per_second': 2.15, 'train_loss': 0.49361161398567305, 'epoch': 2.0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./models/claim_classification_trained_model\n",
      "Configuration saved in ./models/claim_classification_trained_model\\config.json\n",
      "Model weights saved in ./models/claim_classification_trained_model\\pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(save_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrapping (Dev only)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap Functions (Used for dev only; not used in final version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "\n",
    "# Get predicted scores\n",
    "def get_pred_scores(pairs, model, tokenizer):\n",
    "\n",
    "    print(\"Getting prediction scores ...\")\n",
    "\n",
    "    S = []\n",
    "    R = []\n",
    "    NEI = []\n",
    "\n",
    "    text_pairs = [[pairs.iloc[j]['claim_text'], pairs.iloc[j]['ev_text']] for j,_ in pairs.iterrows()]\n",
    "    encodings = tokenizer(text_pairs, \n",
    "                            add_special_tokens=True,\n",
    "                            max_length=128, \n",
    "                            truncation=True, \n",
    "                            padding='max_length', \n",
    "                            return_attention_mask=True, \n",
    "                            return_tensors='pt').to('cuda')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encodings)\n",
    "    for _, score in enumerate(outputs.logits):\n",
    "        S.append(score[0].item())\n",
    "        R.append(score[1].item())\n",
    "        NEI.append(score[2].item())\n",
    "\n",
    "    return S, R, NEI\n",
    "\n",
    "# Get additional ev-claim pairs from bootstraping\n",
    "def get_bootstrap_pairs():\n",
    "\n",
    "    claims = build_claims(my_args.train_claims_path)\n",
    "    if my_args.include_dev:\n",
    "        claims = pd.concat([claims,build_claims(my_args.dev_claims_path)])\n",
    "    evidence = build_evidence(my_args.ev_path)\n",
    "\n",
    "    disputed_claims = claims[claims['claim_label']==\"DISPUTED\"]\n",
    "    NEI_Label = [\"NOT_ENOUGH_INFO\" for i in range(0,len(disputed_claims))]\n",
    "    disputed_claims['claim_label'] = NEI_Label\n",
    "    disputed_pairs = build_pairs(disputed_claims,evidence)\n",
    "\n",
    "    disputed_pairs['S'], disputed_pairs['R'], disputed_pairs['NEI'] = get_pred_scores(disputed_pairs, classifier_model, classifier_tokenizer)\n",
    "    print(\"Disputed pairs analysed:\", len(disputed_pairs))\n",
    "\n",
    "    print(\"Locating max SUPPORTS and REFUTES pairs...\")\n",
    "    bootstrap_pairs = []\n",
    "    unique_claims = disputed_pairs['claim_text'].unique()\n",
    "    s_pairs = []\n",
    "    r_pairs = []\n",
    "    for uc in unique_claims:\n",
    "        grouping = disputed_pairs[disputed_pairs['claim_text'] == uc]\n",
    "        if grouping['S'].max() > 2:\n",
    "            s_pairs.append(grouping['S'].idxmax())\n",
    "        if grouping['R'].max() > 2:\n",
    "            r_pairs.append(grouping['R'].idxmax())\n",
    "\n",
    "    for s in s_pairs:\n",
    "        row = {\n",
    "            \"claim_text\":disputed_pairs.iloc[s]['claim_text'],\n",
    "            \"ev_text\":disputed_pairs.iloc[s]['ev_text'],\n",
    "            \"labels\":0\n",
    "        }\n",
    "        bootstrap_pairs.append(row)\n",
    "    for r in r_pairs:\n",
    "        row = {\n",
    "            \"claim_text\":disputed_pairs.iloc[r]['claim_text'],\n",
    "            \"ev_text\":disputed_pairs.iloc[r]['ev_text'],\n",
    "            \"labels\":1\n",
    "        }\n",
    "        bootstrap_pairs.append(row)\n",
    "\n",
    "    bootstrap_pairs = pd.DataFrame(bootstrap_pairs)\n",
    "    bootstrap_pairs.head()\n",
    "\n",
    "    print(\"Saving %d additional bootstrap pairs to pickle...\" % len(bootstrap_pairs), end='')\n",
    "    with open(my_args.bootstrap_pickle, 'wb') as f:\n",
    "        pickle.dump(bootstrap_pairs, f)\n",
    "    print(\"done.\")\n",
    "\n",
    "# Run bootstrapping training:\n",
    "def run_bootstrapping():\n",
    "    model_name = my_args.cc_model_name\n",
    "    training_name = my_args.cc_training_name\n",
    "    save_dir = my_args.cc_save_dir\n",
    "\n",
    "    print(\"Loading saved model:\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(pretrained_model_name_or_path=save_dir).to('cuda')\n",
    "\n",
    "    dataset = Dataset.from_pandas(bootstrap_pairs)\n",
    "    encoded_dataset = dataset.map(preprocess_function)\n",
    "    encoded_dataset.shuffle()\n",
    "\n",
    "    os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        training_name,\n",
    "        learning_rate=my_args.learning_rate,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        num_train_epochs=1,\n",
    "        weight_decay=0.01,\n",
    "        push_to_hub=False,\n",
    "        report_to=None,\n",
    "        save_strategy='no'\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        args,\n",
    "        train_dataset=encoded_dataset\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    trainer.save_model(save_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_109_NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
